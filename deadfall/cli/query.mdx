---
title: query
description: 'Query the activity log'
---

# deadfall query

Query and search the activity log for specific events, patterns, or time ranges.

## Usage

```bash
deadfall query [options]
```

## Options

| Option | Description | Default |
|:-------|:------------|:--------|
| `--last <duration>` | Time range (e.g., `1h`, `24h`, `7d`) | `24h` |
| `--from <datetime>` | Start time (ISO 8601) | - |
| `--to <datetime>` | End time (ISO 8601) | - |
| `-s, --server <name>` | Filter by server | All |
| `-t, --tool <name>` | Filter by tool name | All |
| `--severity <level>` | Minimum severity: `low`, `medium`, `high`, `critical` | All |
| `--alerts-only` | Show only alert events | `false` |
| `-n, --limit <count>` | Maximum results | `100` |
| `-o, --output <format>` | Output format: `table`, `json`, `csv` | `table` |

## Examples

### Time-Based Queries

```bash
# Last hour
deadfall query --last 1h

# Last 7 days
deadfall query --last 7d

# Specific time range
deadfall query --from "2024-01-15T09:00:00Z" --to "2024-01-15T17:00:00Z"
```

### Filtering

```bash
# Filter by server
deadfall query -s postgres-mcp

# Filter by tool
deadfall query -t execute

# High severity only
deadfall query --severity high

# Only alerts
deadfall query --alerts-only
```

### Output Formats

```bash
# JSON output
deadfall query --last 1h -o json

# CSV for spreadsheets
deadfall query --last 24h -o csv > activity.csv

# Pipe to jq for analysis
deadfall query -o json | jq '.[] | select(.risk == "high")'
```

## Output

### Table Format (Default)

```
$ deadfall query --last 1h --severity high

HIGH SEVERITY EVENTS (last hour)
================================

Time       Severity  Type          Server    Description
---------  --------  ------------  --------  ---------------------------
14:32:01   HIGH      volume_spike  postgres  47x normal query volume
14:32:15   HIGH      new_pattern   postgres  bulk SELECT on users table
14:33:42   CRITICAL  sequence      postgres  read â†’ export detected

3 events found
```

### JSON Format

```json
[
  {
    "timestamp": "2024-01-15T14:32:01Z",
    "server": "postgres-mcp",
    "tool": "query",
    "severity": "high",
    "type": "volume_spike",
    "details": {
      "observed": 470,
      "baseline": 10,
      "ratio": 47
    }
  }
]
```

## Aggregations

```bash
# Count by server
deadfall query --last 7d -o json | jq 'group_by(.server) | map({server: .[0].server, count: length})'

# Count by severity
deadfall query --last 24h -o json | jq 'group_by(.severity) | map({severity: .[0].severity, count: length})'
```

## Performance

For large time ranges, consider:

```bash
# Limit results
deadfall query --last 30d -n 1000

# Export incrementally
deadfall export --from "2024-01-01" --to "2024-01-31" -o january.json
```
